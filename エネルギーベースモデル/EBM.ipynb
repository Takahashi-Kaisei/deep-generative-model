{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エネルギーベースモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意の$\\boldsymbol{x} \\in \\mathbb{R}_D$を入力としてとる，エネルギー関数を考える．\n",
    "\n",
    "$E_{\\theta}:\\mathbb{R}_D \\rightarrow \\mathbb{R}$\n",
    "\n",
    "エネルギーベースモデル\n",
    "$$\n",
    "p_{\\theta}(\\boldsymbol{x}) = \\frac{1}{Z_{\\theta}}\\exp(-E_{\\theta}(\\boldsymbol{x}))\n",
    "$$\n",
    "\n",
    "ここで，$Z_{\\theta}$は正規化定数であり，次のように定義される．\n",
    "$$\n",
    "Z_{\\theta} = \\int \\exp(-E_{\\theta}(\\boldsymbol{x}))d\\boldsymbol{x}\n",
    "$$\n",
    "\n",
    "この形式の分布は，統計物理におけるボルツマン分布と呼ばれる．\n",
    "\n",
    "エネルギーを反転させた関数を，ハーモニー関数と呼ぶ．\n",
    "\n",
    "統計物理では，エネルギーが低い状態が安定状態なので，マイナスをつけて低い値が尤度最大に対応させる．\n",
    "\n",
    "\n",
    "確率変数$x, y$をもつEBMの同時分布は，\n",
    "$$\n",
    "p_{\\theta}(x, y) = \\frac{1}{Z_{\\theta}}\\exp(-E_{\\theta}(\\boldsymbol{x}, \\boldsymbol{y}))\n",
    "$$\n",
    "\n",
    "$E_{\\theta}(\\boldsymbol{x}, \\boldsymbol{y})$は，両変数の適合性を表す．\n",
    "\n",
    "変数間の方向を定義しないので，無向モデル\n",
    "\n",
    "\n",
    "クリーク：全てが互いに接続されているノードの部分集合．\n",
    "\n",
    "一般に，$\\boldsymbol{x}$の無向モデルは，グラフのクリークごとの因子によって定義される．\n",
    "\n",
    "いっぱい変数がある時は，クリークごとに変数間の県警を考えるだけ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "潜在変数を持つEBM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "潜在変数＄\\boldsymbol{z}$と，観測変数$\\boldsymbol{x}$を持つEBMの同時分布は，\n",
    "$$\n",
    "p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}) = \\frac{1}{Z_{\\theta}}\\exp(-E_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}))\n",
    "$$\n",
    "\n",
    "これを周辺化．\n",
    "\n",
    "$$\n",
    "p_{\\theta}(\\boldsymbol{x}) = \\int p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})d\\boldsymbol{z}\n",
    "$$\n",
    "\n",
    "自由エネルギーを導入する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習の仕方はデータ分布からのサンプルのエネルギーと，モデル分布からのサンプルのエネルギーで計算．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative Phaseでは，生成モデルからのサンプリングが必要であることがわかる．\n",
    "\n",
    "生成モデルからどうやってサンプリングするねん．\n",
    "\n",
    "→モデルの構造を工夫することが多い．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ボルツマンマシン\n",
    "\n",
    "さっきの生成モデルからのサンプリングのための，工夫した構造．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNNによるEBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ボルツマンマシン自体は，最近では使われることは少なくなった．\n",
    "\n",
    "したがって今回は，EBMにおいて，モダンなDNNを使用していく方法を考える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "制約付きボルツマンマシンなどでは，高次元のデータを扱えない．\n",
    "\n",
    "そこで，DNNでエネルギー関数をパラメータ化する．\n",
    "\n",
    "入力をデータ，出力をスカラー値のエネルギーとする．\n",
    "\n",
    "問題\n",
    "- 結局EBMで一番難しいのは，モデル分布からのサンプリング．\n",
    "\n",
    "ここをどうするか．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ランジェバンダイナミクス\n",
    "\n",
    "生成モデルからのサンプリングを，次のように反復的に行う．\n",
    "\n",
    "あとで修正↓\n",
    "$$\n",
    "\\boldsymbol{x}^{(t+1)} = \\boldsymbol{x}^{(t)} + \\epsilon \\frac{\\partial E_{\\theta}(\\boldsymbol{x}^{(t)})}{\\partial \\boldsymbol{x}^{(t)}}\n",
    "$$\n",
    "\n",
    "これはある意味ギブスサンプリングの連続値版と言える．\n",
    "MCMCの一種．\n",
    "\n",
    "ノイジーな勾配降下法みたいなもの．\n",
    "\n",
    "これをやると安定してサンプリングすることができる．\n",
    "\n",
    "ノイズがだんだん取れていくような挙動はまさにLDの過程．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDを使うのは変わらないけど，もっと安定化するために，いろいろな手法がある．\n",
    "\n",
    "- LDの初期値を一葉分布だけでなく，過去のサンプル効果も利用．\n",
    "\n",
    "- エネルギー関数へのリプシッツ制約(GANを参照)やL2正則化を加える．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同時分布の対数尤度を最大化してやると，生成モデルと識別モデルどちらも学習できる．\n",
    "\n",
    "これで，生成モデル，識別モデルどちらも得ることができる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBMの利点と欠点\n",
    "- 利点\n",
    "    - アーキテクチャの制約が少ない\n",
    "    - 単一のモデルで安定した学習ができる．\n",
    "    - 計算コスト，生成のクオリティを調整できる．(LDのステップ数によって)\n",
    "- 欠点\n",
    "    - 尤度を明示的に計算できない．(フローベース，自己回帰に比べての欠点)\n",
    "    - 生成するためには，反復的な確率最適化が必要．(LDを毎回毎回回さないといけない．)\n",
    "\n",
    "近年，様々なEBMの研究が進められている．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
